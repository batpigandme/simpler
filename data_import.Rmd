# (PART) Data Import and Export {-}

# Tutorial format

From hereonin we're going to be focusing on using R, rather than the history, community and everything else. One approach to teaching a programming language is to step through the different rules in how the language is constructed, what the different keywords are, any strange quirks it has, and all the rest - and this can be really helpful for people who are *already* programmers.

That isn't guaranteed, though, and so the rest of this book is divided up into individual, practical applications of the language, combined with explanations of what's going on in each piece so that you can learn the structure of the language through doing.

So, going forward, you'll see something that looks like the following; I'll introduce a concept, or a step in analysing data, and talk about why it's important. And then, after a colon, because I flagrantly abuse both the colon and semicolon:

```{r, eval=FALSE}
There'll be a chunk of code, in a shaded box just like this one,
which will achieve the step I was talking about
```

After that will be an explanation of that chunk of code, and what each bit is doing and how everything in it works. If you're the sort of person who instead wants to jump into the nitty-gritty of the language, I recommend Hadley Wickham's *[Advanced R Programming](http://adv-r.had.co.nz/Data-structures.html)* (specifically the data structures section) to get a handle for the general workings of R, and then coming back here to learn the applications.

# Reading data from files

Obviously the first step in data analysis is getting the data, so let's start there! Datasets come in lots of different formats, so we'll cover the ones you most commonly see in a business context, namely:

1. Comma-separated and tab-separated values files (CSV/TSV);
2. Microsoft Excel spreadsheets;
3. MySQL and similar databases.

## CSV & TSV

CSVs and TSVs are the most common file format for data, and the good news there is that as a consequence, R has a whole host of tools for reading them in. Let's open by loading one of them: the `readr` add-on I had you install earlier:

```{r, eval=FALSE}
library(readr)
```

So, what's this code doing? First, `library`; that's a function, which is a self-contained chunk of code that's packaged and made available so you can use it as many times as you want without having to write the code out entirely each time. `readr` is the input provided to `library`. So it works out as `do_this_thing(to_this_thing)`.

The `library` function loads *packages* - the add-ons I was talking about earlier - so you can refer to the code they contain when you're working. In this case it's loading `readr`, a package specifically designed for reading in and writing out a wide range of file formats, including CSVs and TSVs.

When you see a function name, you can usually access documentation about it; remember the `help` pane I mentioned earlier? If you type the function name into the console, preceded by `?`, the help pane will pop up with documentation for that function - what it's used for, what values it accepts, and generally how it works.

So we have our file-reading code. Now let's read in the file, with:

```{r, eval=FALSE}
patient_data <- read_csv(file = "https://www.ironholds.org/resources/misc/patient_data.csv")
```

Let's break down what's going on in that code, going from right to left. First we have a piece of text - a URL, in fact - in quote marks. The quote marks identify the text as a `string`; something that R should treat just as text, not as code to be executed. Then we have that URL being associated with "file", the entire thing wrapped in parentheses, preceded by `read_csv` which, as we've seen from loading the `readr` package, is a function call.

So what we have is a call to run `read_csv`, with the "file" argument being that URL - so it's reading a CSV from that URL! The argument, as the name `file` suggests, doesn't have to be a URL; it can also be a file on your local computer.

Then we shift left and run into `<-`. That's R's *assignment operator*; it assigns the results of whatever code is on the right of the operator, to a name on the left of it (in this case, `patient_data`). So the code, in plain English, is "read in the CSV at this URL and assign the contents of it to the name `patient_data`". If the file was a TSV, the process would look exactly the same; you'd just use `read_tsv` instead of `read_csv`.

We call the result (the output of code, tied to a name) an *object*. You can see the contents of an object just by typing its name into the console, but that shows the entire thing, and this dataset is rather large; instead, let's use the `head` function, which just shows the top few rows (the head of the data):

```{r, eval=FALSE}
head(patient_data)


  year facility_number    facility_name county_name type_of_control age_group count
1 2009          010735 ALAMEDA HOSPITAL     ALAMEDA        District     10-19    62
2 2009          010735 ALAMEDA HOSPITAL     ALAMEDA        District     20-29   124
3 2009          010735 ALAMEDA HOSPITAL     ALAMEDA        District     30-39   140
4 2009          010735 ALAMEDA HOSPITAL     ALAMEDA        District     40-49   243
5 2009          010735 ALAMEDA HOSPITAL     ALAMEDA        District     50-59   411
6 2009          010735 ALAMEDA HOSPITAL     ALAMEDA        District     60-69   415
```

As you can see, it's tabular, just like the CSV - columns of values, rows of observations, and row numbers (from 1 to 6). What you're looking at is a "data frame", the most common type of object in R: it's designed to hold tabular data, since tabular data is what most statisticians and data scientists rely on.

We can get a more detailed look at it with the `str` function (which means "structure" and does exactly what it says on the tin):

```{r, eval=FALSE}
str(patient_data)

Classes ‘tbl_df’, ‘tbl’ and 'data.frame':	23578 obs. of  7 variables:
 $ year           : int  2009 2009 2009 2009 2009 2009 2009 2009 2009 2009 ...
 $ facility_number: chr  "010735" "010735" "010735" "010735" ...
 $ facility_name  : chr  "ALAMEDA HOSPITAL" "ALAMEDA HOSPITAL" "ALAMEDA HOSPITAL" "ALAMEDA HOSPITAL" ...
 $ county_name    : chr  "ALAMEDA" "ALAMEDA" "ALAMEDA" "ALAMEDA" ...
 $ type_of_control: chr  "District" "District" "District" "District" ...
 $ age_group      : chr  "10-19" "20-29" "30-39" "40-49" ...
 $ count          : int  62 124 140 243 411 415 486 961 7743 788 ...
```

There's a lot going on here, so let's break it down:

1. First, "classes"; this is analogous to the object type. We don't have to dig into exactly how the system works (although feel free to ask me about it via email or do further research); the important thing to note is that one of the classes is `data.frame`, identifying this as, well, a data frame!
2. We then have "23578 obs. of 7 variables"; there are 23,578 rows, and 7 columns. You can get these bits of information distinctly, through the `nrow` and `ncol` functions.
3. We then have a sort of flipped version of the `head` output - showing columns from left to right. There are the column names (`year`, `facility_number`, `facility_name`), examples of the entries in those columns, and then these little strings "int" and "chr". These represents the "type" of the column - the type of data it can contain. `int` columns contain whole numbers; `chr` (or "character") columns contain strings. Other common types to see are `logical` (or `logi`), which contains true and false values, and `numeric`/`num` columns, which contain non-whole numbers.

So now we have our data read into R. It's not quite perfect, though; the `facility_number` column is meant to be, well, a column of numbers, but according to `str` it's actually a character column. This offers us an opportunity to explore modifying data frames, and switching between types.

Let's cover both at once. One of the reasons data frames are powerful is that you can access, change and use individual columns, as well as the data frame as a whole; this is done by calling, instead of `data_frame_name`, `data_frame_name$column_name`. Distinctly from that, it is possible to change the type of an object in R (the process is known as `coercing`), which can be very useful; depending on what you're doing, you might want to store a value as a different type. Coersion is done with the `as` functions; `as.numeric` to turn something into a numeric value, `as.integer` for an integer, and then `as.logical` and `as.character` for those respective types.

Let's use both techniques now, to clear up that `facility_number` column:

```{r, eval=FALSE}
patient_data$facility_number <- as.integer(patient_data$facility_number)

str(patient_data)

Classes ‘tbl_df’, ‘tbl’ and 'data.frame':	23578 obs. of  7 variables:
 $ year           : int  2009 2009 2009 2009 2009 2009 2009 2009 2009 2009 ...
 $ facility_number: int  10735 10735 10735 10735 10735 10735 10735 10735 10739 10739 ...
 $ facility_name  : chr  "ALAMEDA HOSPITAL" "ALAMEDA HOSPITAL" "ALAMEDA HOSPITAL" "ALAMEDA HOSPITAL" ...
 $ county_name    : chr  "ALAMEDA" "ALAMEDA" "ALAMEDA" "ALAMEDA" ...
 $ type_of_control: chr  "District" "District" "District" "District" ...
 $ age_group      : chr  "10-19" "20-29" "30-39" "40-49" ...
 $ count          : int  62 124 140 243 411 415 486 961 7743 788 ...
```

As you can see, `facility_number` is now an integer column, which lets us (amongst other things) do maths with it if we so choose - tremendously useful.

We can also add new columns to data frames using a similar technique, and take advantage of a feature of R called "vectorisation". The easiest way to think about it is Excel-related. You have your Excel spreadsheet, and you create a formula in one cell to add up all the values in that row. You want to do that for every row, so you drag the formula down the column and it copies the formula out, ending up with something like:

```
A1 + A2
B1 + B2
C1 + C2
```

Vectorisation is just that - except it's automated. No dragging and dropping required! Most R functions automatically work on entire columns of data, and work when you have a column on one side but only a single value on the other. Let's combine that with data frame modification to work out the *percentage* of the total count of patients in each row:

```
patient_data$percentage <- patient_data$count / sum(patient_data$count)

str(patient_data)

Classes ‘tbl_df’, ‘tbl’ and 'data.frame':	23578 obs. of  8 variables:
 $ year           : int  2009 2009 2009 2009 2009 2009 2009 2009 2009 2009 ...
 $ facility_number: int  10735 10735 10735 10735 10735 10735 10735 10735 10739 10739 ...
 $ facility_name  : chr  "ALAMEDA HOSPITAL" "ALAMEDA HOSPITAL" "ALAMEDA HOSPITAL" "ALAMEDA HOSPITAL" ...
 $ county_name    : chr  "ALAMEDA" "ALAMEDA" "ALAMEDA" "ALAMEDA" ...
 $ type_of_control: chr  "District" "District" "District" "District" ...
 $ age_group      : chr  "10-19" "20-29" "30-39" "40-49" ...
 $ count          : int  62 124 140 243 411 415 486 961 7743 788 ...
 $ percentage     : num  2.66e-06 5.32e-06 6.01e-06 1.04e-05 1.76e-05 ...
```

No drag and drop necessary; the `patient_data` data frame has a new column, `percentage`, which contains (for each row) the `count` divided by the total count for the entire dataset, which we retrieved with `sum`.

So we now know:

1. How to read data into R from CSV files (and TSV files!);
2. How to examine the structure of an R object;
2. How do access individual columns of a data frame;
3. How to modify those columns, and create new ones;
4. How vectorisation works.

Let's move on to everyone's favourite business data format: Microsoft Excel!

## Excel

As you know, Microsoft Excel was so named because it represented a tremendous amount of effort (Excel) being pushed into a business model centred on producing eyewatering data formats (Microsoft). The result, unsurprisingly, is a paragon of eye-wateringly awfully formatted data.

Despite this it's widely used in a business context, so we should learn how to read those files into R. If we can read them into R, we can close Excel and never use it again, and isn't that everyone's dream?


## Other types

# Reading data from databases

# Exporting data
