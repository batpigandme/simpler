[
["index.html", "Starting Out with R and Shiny Preamble", " Starting Out with R and Shiny Oliver Keyes Preamble Welcome to Starting Out with R and Shiny, a guide to learning basic R and ending up with the ability to put together Shiny dashboards - online, R-based dashboards and visualisations. This set of documentation is being written for a set of lectures in Springfield, IL, and is primarily aimed at attendees, but it will hopefully be useful to others too. It contains (or will contain): An introduction to R as a language, its history, and its structure; A basic guide to RStudio and online help resources for questions, bugs or commentary; Importing data into R from databases or flat files; Cleaning and reshaping that data with tidyr, dplyr, stringi, lubridate and related tools; Shiny as a data visualisation platform; Miscellaneous more-advanced tips and tricks on writing and running R and Shiny in a reliable manner. "],
["background.html", "Chapter 1 Background 1.1 A brief history of splines 1.2 Why R succeeds 1.3 The R community", " Chapter 1 Background 1.1 A brief history of splines The R programming language started off at the University of Auckland, where two statistics professors - Ross Ihaka and Robert Gentleman - found themselves somewhat perturbed by the state of statistical programming. There were a lot of statistical languages and environments out there, but most of the ones they had access to were commercial, requiring you to pay to use them. In the end they decided to write something themselves, and they called it R (first because it’s the first letter in both of their names and second, I hypothesise, because after you’ve written an entire programming language with one other person you probably don’t have the energy left to come up with a fancy name). It was initially used just by the two of them in teaching courses at Auckland, and student complaints were the main source of improvements. In June 1995, though, everything changed when they released the source code of the language online - and did so under a free license, which let other people reuse the code and crucially modify the code. People began submitting their own improvements, new features, and bug fixes, and the language grew and grew. By 2012 it was the most commonly used data science language - a status it continues to maintain to this day.ref 1.2 Why R succeeds R didn’t become popular in a vacuum; there are a lot of other solutions for data analysis out there, some commercial (SAS, SPSS) and some open source (MATLAB, Python, Julia). Despite that, R consistently outstrips them in popularity, and there are a few reasons for that. R was written by statisticians. A lot of programming languages (including statistical ones) are written, unsurprisingly, by programmers - and this is great from a software engineering standpoint. R, however, was written by statisticians, and while this means the language looks slightly strange compared to more “proper” programming languages, it means that it’s designed from the ground up to handle the things that statisticians and scientists need. The primary data formats are tabular, just like the results from scientific experiments tend to be; the language has not only arithmetic support, but also significance tests, general modelling functions and matrix mathematics built in. R was written by a community. As well as the base language, which is the work of many hands, there’s also an entire ecosystem of add-ons (which we’ll cover later). Put simply: if there’s something statistical you need to do, and it isn’t in R itself, it’s almost certainly in an add-on - one that you can obtain, use and include in your work completely free of charge. R can do pretty much everything. It’s primarily a statistical language, but it’s not just a statistical language. You can do data analysis in it, sure. You can also visualise the results of that analysis in a thousand different ways. Or write reports based on it that turn out as LaTeX, PDFs, HTML, Markdown. or build dynamic, web-hosted visualisations and dashboards and interactive platforms to display your work. Heck, you can even build websites in it; I did just to see if I could, and it took 40 lines of code. Although in that specific case, while you could use R, I would strongly recommend you don’t. The point, though, is that while R is primarily about statistics, it’s a language that covers pretty much every step of handling data, from reading it in and cleaning it up to showing your results to the world. R can interact with pretty much everything. That’s a slight exaggeration, but only slight. Suppose someone gives you code written in C? R can interact with that. FORTRAN? Yep. C++? Absolutely! And while we’re at it, you can link R into Python, JavaScript, Java, Scala, and a whole host of other languages. This means that on the off-chance you encounter something you really need to do that isn’t in R, you can integrate it in pretty easily. There are a lot of other fascinating and wonderful features (some of which we’ll cover later on!) but those are the main ones, and why after writing thousands upon thousands of lines of R in the last few years, I’m still so in love with it. 1.3 The R community One of the things I touched on above - as a reason R is such a powerful and popular environment - is the community. A big benefit is the expertise that community has: for example, the R add-on for neural networks was written by Brian Ripley, a British statistician who quite literally wrote the book on neural networks, and having the person who invented the methodology implement it gives you a pretty strong claim to the implementation being reliable. But another benefit is simply that, while there are dragons in some corners, the community generally consists of people who love expanding what the language can do and how friendly to new users it is - and they practise what they preach! And there are a lot of R programmers, and a lot of places to get help, support, suggestions and pointers. Some venues worth keeping in mind, in case you run into a problem and need some assistance, are: R on StackOverflow; R’s official mailing lists, and; the R IRC channel. "],
["getting-set-up.html", "Chapter 2 Getting set up 2.1 Installation 2.2 Using RStudio", " Chapter 2 Getting set up 2.1 Installation To get started with R, you’re going to need…well, R! If you’re on Windows you can get R here; if you’re on a mac, you can download it here. For Linux users (specifically Ubuntu users, or people on other, Debian-based distributions) open the terminal and type: sudo apt-get -y install r-base This requires the password to your computer’s administrator account; if you don’t have it, you’ll need to get the system administrator to install R. Once you’ve got R, you’ll also need RStudio - an Integrated Development Environment (IDE) for R that we’ll be covering shortly. RStudio can be obtained here. After that, you’ll need a few R packages (more on those later) that are used in this tutorial. Open RStudio, now that you’ve installed it, and go to the window in the bottom left marked “console”. Type: install.packages(&quot;readr&quot;, &quot;dplyr&quot;, &quot;tidyr&quot;, &quot;readxl&quot;, &quot;shinydashboard&quot;, &quot;magrittr&quot;) (Don’t worry about what this means right now; we’ll get to it later) 2.2 Using RStudio You should now have RStudio; that’s going to be your primary interface for writing R in. Let’s briefly step through the important bits of the program that you should be paying attention to. When you open it up there should be three different panes, nestled inside the program, looking something like this: Let’s step through each of them in turn. Going clockwise, we first have the console: this is a window into which you can type R commands, and see the output - we’ll be using that a lot. Next over, we’ve got a pane with two tabs; “Environment” (the default) and “History”. “Environment” contains a listing of everything you create during your R tinkering, while “History” provides, well, a history, of the commands you’ve typed into the console: that way if you need to re-run something, you can find it easily. And, last but not least down in the bottom left, we have “Files” (which shows your filesystem, so you can find R scripts you’ve already saved or datasets you want to read in) , “Plots”, which will contain any visualisations you generate so that you can prototype them, “Packages”, which lists all the R add-ons on your system (and which are loaded), and “Help”, which shows any documentation you request. In practice, another tab will open up when you have an R script open, where the top of “console” is now, and this will contain whatever file(s) you’re editing. For now, though, let’s focus on the console. "],
["tutorial-format.html", "Chapter 3 Tutorial format", " Chapter 3 Tutorial format From hereonin we’re going to be focusing on using R, rather than the history, community and everything else. One approach to teaching a programming language is to step through the different rules in how the language is constructed, what the different keywords are, any strange quirks it has, and all the rest - and this can be really helpful for people who are already programmers. That isn’t guaranteed, though, and so the rest of this book is divided up into individual, practical applications of the language, combined with explanations of what’s going on in each piece so that you can learn the structure of the language through doing. So, going forward, you’ll see something that looks like the following; I’ll introduce a concept, or a step in analysing data, and talk about why it’s important. And then, after a colon, because I flagrantly abuse both the colon and semicolon: There&#39;ll be a chunk of code, in a shaded box just like this one, which will achieve the step I was talking about After that will be an explanation of that chunk of code, and what each bit is doing and how everything in it works. If you’re the sort of person who instead wants to jump into the nitty-gritty of the language, I recommend Hadley Wickham’s Advanced R Programming (specifically the data structures section) to get a handle for the general workings of R, and then coming back here to learn the applications. "],
["reading-data-from-files.html", "Chapter 4 Reading data from files 4.1 CSV &amp; TSV 4.2 Excel 4.3 Other files", " Chapter 4 Reading data from files Obviously the first step in data analysis is getting the data, so let’s start there! Datasets come in lots of different formats, so we’ll cover the ones you most commonly see in a business context, namely: Comma-separated and tab-separated values files (CSV/TSV); Microsoft Excel spreadsheets; MySQL and similar databases. 4.1 CSV &amp; TSV CSVs and TSVs are the most common file format for data, and the good news there is that as a consequence, R has a whole host of tools for reading them in. Let’s open by loading one of them: the readr add-on I had you install earlier: library(readr) So, what’s this code doing? First, library; that’s a function, which is a self-contained chunk of code that’s packaged and made available so you can use it as many times as you want without having to write the code out entirely each time. readr is the input provided to library. So it works out as do_this_thing(to_this_thing). The library function loads packages - the add-ons I was talking about earlier - so you can refer to the code they contain when you’re working. In this case it’s loading readr, a package specifically designed for reading in and writing out a wide range of file formats, including CSVs and TSVs. When you see a function name, you can usually access documentation about it; remember the help pane I mentioned earlier? If you type the function name into the console, preceded by ?, the help pane will pop up with documentation for that function - what it’s used for, what values it accepts, and generally how it works. So we have our file-reading code. Now let’s read in the file, with: patient_data &lt;- read_csv(file = &quot;https://www.ironholds.org/resources/misc/patient_data.csv&quot;) Let’s break down what’s going on in that code, going from right to left. First we have a piece of text - a URL, in fact - in quote marks. The quote marks identify the text as a string; something that R should treat just as text, not as code to be executed. Then we have that URL being associated with “file”, the entire thing wrapped in parentheses, preceded by read_csv which, as we’ve seen from loading the readr package, is a function call. So what we have is a call to run read_csv, with the “file” argument being that URL - so it’s reading a CSV from that URL! The argument, as the name file suggests, doesn’t have to be a URL; it can also be a file on your local computer. Then we shift left and run into &lt;-. That’s R’s assignment operator; it assigns the results of whatever code is on the right of the operator, to a name on the left of it (in this case, patient_data). So the code, in plain English, is “read in the CSV at this URL and assign the contents of it to the name patient_data”. If the file was a TSV, the process would look exactly the same; you’d just use read_tsv instead of read_csv. We call the result (the output of code, tied to a name) an object. You can see the contents of an object just by typing its name into the console, but that shows the entire thing, and this dataset is rather large; instead, let’s use the head function, which just shows the top few rows (the head of the data): head(patient_data) year facility_number facility_name county_name type_of_control age_group count 1 2009 010735 ALAMEDA HOSPITAL ALAMEDA District 10-19 62 2 2009 010735 ALAMEDA HOSPITAL ALAMEDA District 20-29 124 3 2009 010735 ALAMEDA HOSPITAL ALAMEDA District 30-39 140 4 2009 010735 ALAMEDA HOSPITAL ALAMEDA District 40-49 243 5 2009 010735 ALAMEDA HOSPITAL ALAMEDA District 50-59 411 6 2009 010735 ALAMEDA HOSPITAL ALAMEDA District 60-69 415 As you can see, it’s tabular, just like the CSV - columns of values, rows of observations, and row numbers (from 1 to 6). What you’re looking at is a “data frame”, the most common type of object in R: it’s designed to hold tabular data, since tabular data is what most statisticians and data scientists rely on. We can get a more detailed look at it with the str function (which means “structure” and does exactly what it says on the tin): str(patient_data) Classes ‘tbl_df’, ‘tbl’ and &#39;data.frame&#39;: 23578 obs. of 7 variables: $ year : int 2009 2009 2009 2009 2009 2009 2009 2009 2009 2009 ... $ facility_number: chr &quot;010735&quot; &quot;010735&quot; &quot;010735&quot; &quot;010735&quot; ... $ facility_name : chr &quot;ALAMEDA HOSPITAL&quot; &quot;ALAMEDA HOSPITAL&quot; &quot;ALAMEDA HOSPITAL&quot; &quot;ALAMEDA HOSPITAL&quot; ... $ county_name : chr &quot;ALAMEDA&quot; &quot;ALAMEDA&quot; &quot;ALAMEDA&quot; &quot;ALAMEDA&quot; ... $ type_of_control: chr &quot;District&quot; &quot;District&quot; &quot;District&quot; &quot;District&quot; ... $ age_group : chr &quot;10-19&quot; &quot;20-29&quot; &quot;30-39&quot; &quot;40-49&quot; ... $ count : int 62 124 140 243 411 415 486 961 7743 788 ... There’s a lot going on here, so let’s break it down: First, “classes”; this is analogous to the object type. We don’t have to dig into exactly how the system works (although feel free to ask me about it via email or do further research); the important thing to note is that one of the classes is data.frame, identifying this as, well, a data frame! We then have “23578 obs. of 7 variables”; there are 23,578 rows, and 7 columns (which, in R, are known as vectors - more on those later). You can get these bits of information distinctly, through the nrow and ncol functions. We then have a sort of flipped version of the head output - showing each vector, from the first to the last, down. There are the vector names (year, facility_number, facility_name), examples of the entries in those columns, and then these little strings “int” and “chr”. These represents the “type” of the column - the type of data it can contain. int vectors contain whole numbers; chr (or “character”) vectors contain strings. Other common types to see are logical (or logi), which contains true and false values, and numeric/num columns, which contain non-whole numbers. So now we have our data read into R. It’s not quite perfect, though; the facility_number vector is meant to be, well, a column of numbers, but according to str it’s actually a character vector. This offers us an opportunity to explore modifying data frames, and switching between types. Let’s cover both at once. One of the reasons data frames are powerful is that you can access, change and use individual vectors, as well as the data frame as a whole; this is done by calling, instead of data_frame_name, data_frame_name$column_name. Distinctly from that, it is possible to change the type of an object in R (the process is known as coercing), which can be very useful; depending on what you’re doing, you might want to store a value as a different type. Coersion is done with the as functions; as.numeric to turn something into a numeric value, as.integer for an integer, and then as.logical and as.character for those respective types. Let’s use both techniques now, to clear up that facility_number vector: patient_data$facility_number &lt;- as.integer(patient_data$facility_number) str(patient_data) Classes ‘tbl_df’, ‘tbl’ and &#39;data.frame&#39;: 23578 obs. of 7 variables: $ year : int 2009 2009 2009 2009 2009 2009 2009 2009 2009 2009 ... $ facility_number: int 10735 10735 10735 10735 10735 10735 10735 10735 10739 10739 ... $ facility_name : chr &quot;ALAMEDA HOSPITAL&quot; &quot;ALAMEDA HOSPITAL&quot; &quot;ALAMEDA HOSPITAL&quot; &quot;ALAMEDA HOSPITAL&quot; ... $ county_name : chr &quot;ALAMEDA&quot; &quot;ALAMEDA&quot; &quot;ALAMEDA&quot; &quot;ALAMEDA&quot; ... $ type_of_control: chr &quot;District&quot; &quot;District&quot; &quot;District&quot; &quot;District&quot; ... $ age_group : chr &quot;10-19&quot; &quot;20-29&quot; &quot;30-39&quot; &quot;40-49&quot; ... $ count : int 62 124 140 243 411 415 486 961 7743 788 ... As you can see, facility_number is now an integer vector, which lets us (amongst other things) do maths with it if we so choose - tremendously useful. We can also add new vectors to data frames using a similar technique, and take advantage of a feature of R called “vectorisation”. The easiest way to think about it is Excel-related. You have your Excel spreadsheet, and you create a formula in one cell to add up all the values in that row. You want to do that for every row, so you drag the formula down the column and it copies the formula out, ending up with something like: A1 + A2 B1 + B2 C1 + C2 Vectorisation is just that - except it’s automated. No dragging and dropping required! Most R functions automatically work on entire vectors of data, and work when you have a vectors on one side but only a single value on the other. Let’s combine that with data frame modification to work out the percentage of the total count of patients in each row: patient_data$percentage &lt;- patient_data$count / sum(patient_data$count) str(patient_data) Classes ‘tbl_df’, ‘tbl’ and &#39;data.frame&#39;: 23578 obs. of 8 variables: $ year : int 2009 2009 2009 2009 2009 2009 2009 2009 2009 2009 ... $ facility_number: int 10735 10735 10735 10735 10735 10735 10735 10735 10739 10739 ... $ facility_name : chr &quot;ALAMEDA HOSPITAL&quot; &quot;ALAMEDA HOSPITAL&quot; &quot;ALAMEDA HOSPITAL&quot; &quot;ALAMEDA HOSPITAL&quot; ... $ county_name : chr &quot;ALAMEDA&quot; &quot;ALAMEDA&quot; &quot;ALAMEDA&quot; &quot;ALAMEDA&quot; ... $ type_of_control: chr &quot;District&quot; &quot;District&quot; &quot;District&quot; &quot;District&quot; ... $ age_group : chr &quot;10-19&quot; &quot;20-29&quot; &quot;30-39&quot; &quot;40-49&quot; ... $ count : int 62 124 140 243 411 415 486 961 7743 788 ... $ percentage : num 2.66e-06 5.32e-06 6.01e-06 1.04e-05 1.76e-05 ... No drag and drop necessary; the patient_data data frame has a new column, percentage, which contains (for each row) the count divided by the total count for the entire dataset, which we retrieved with sum. So we now know: How to read data into R from CSV files (and TSV files!); How to examine the structure of an R object; How do access individual columns of a data frame; How to modify those columns, and create new ones; How vectorisation works. Let’s move on to everyone’s favourite business data format: Microsoft Excel! 4.2 Excel Microsoft Excel is widely used in a business context, and correspondingly the data it outputs (.xls and .xlsx files) are widely distributed. We should learn how to read them into R, which is a big step in shifting away from Excel-based workflows and ensures that you can consume data from more traditional sources without running into format incompatibilities. For this we’ll need another R package, readxl, which does just that - reads in Excel files. Let’s load it and read in a file that the package ships with (which we can find with the system.file function): library(readxl) excel_data &lt;- read_excel(path = system.file(&quot;extdata/datasets.xlsx&quot;, package = &quot;readxl&quot;)) head(excel_data) Sepal.Length Sepal.Width Petal.Length Petal.Width Species 1 5.1 3.5 1.4 0.2 setosa 2 4.9 3.0 1.4 0.2 setosa 3 4.7 3.2 1.3 0.2 setosa 4 4.6 3.1 1.5 0.2 setosa 5 5.0 3.6 1.4 0.2 setosa 6 5.4 3.9 1.7 0.4 setosa It’s another data frame - as expected, since excel spreadsheets are tabular just like CSV files are. One important note - Excel spreadsheets can contain multiple sheets, each of them a table. How do we handle that? If you look at the documentation for read_excel, you’ll see a sheet argument, which you can use to specify which sheet to read in. The excel_sheets function, meanwhile, gets you how many sheets an Excel file has. So we can combine them to work out how many sheets we’re looking at, and then read in that many. But what happens when you have to write code that reads in a variety of different files, some with different numbers of sheets? How do we write code that doesn’t mind how many sheets there are? How do we store the results of that code? A few new concepts and pieces of R, for this question. First-off is how we’re going to store the results. We’re looking at an unknown number of sheets, which means an unknown number of data frames. Luckily, data frames can be stored as components of a single object, just like vectors are components of data frames. That means instead of having an unknown number of objects, we just have one. For that kind of storage, we’re going to introduce a new object type in R: lists. Lists can have any length you want, and contain pretty much any object you want, too, which makes them extremely powerful. You can construct and use them with, or without names. # A list without names nameless_list &lt;- list(2, 3) # A list with names named_list &lt;- list(first_object = 2, second_object = 3) The difference is how you get objects inside the list, or change those objects: if the list has names, you can use the $ character we use with data frame contents. If it doesn’t, you have to use indices - getting the Nth element of the object by pointing to [[N]]. Taking the list examples we created above: nameless_list[[1]] [1] 2 named_list$first_object [1] 2 So now we know how to store the results. But how do we get them? First, we need to have a way of automatically knowing how many sheets there are. We can do that with another readxl function, excel_sheets, which lists all the sheets in an Excel file: sheet_names &lt;- excel_sheets(path = system.file(&quot;extdata/datasets.xlsx&quot;, package = &quot;readxl&quot;)) sheet_names [1] &quot;iris&quot; &quot;mtcars&quot; &quot;chickwts&quot; &quot;quakes&quot; Then we need a way of taking that vector of sheet names, and, for each one, reading in that sheet, and storing all the results in a list. The answer is the lapply function. lapply takes a list (or vector), X and, for each element of X, performs a specified operation using it. The results of each operation on each element is then returned in a list. Perfect! So what we want is: sheet_names &lt;- excel_sheets(path = system.file(&quot;extdata/datasets.xlsx&quot;, package = &quot;readxl&quot;)) all_sheets &lt;- lapply(X = sheet_names, FUN = read_excel, path = system.file(&quot;extdata/datasets.xlsx&quot;, package = &quot;readxl&quot;)) If you run str on the results of that, what you should see is that all_sheets is a list, containing 4 data frames, all of which contain a pile of columns and rows just like our example at the beginning. These data frames can be extracted using the indices operation; all_sheets[[1]] gets you the first sheet, and so on, and so forth. So now we’ve learned how to read in Excel files. We’ve also learned: What lists are (and how they can be used to store a variety of objects); How to apply a function to each element of a list (or vector); How to get the results of that application. 4.3 Other files "],
["reading-data-from-databases.html", "Chapter 5 Reading data from databases", " Chapter 5 Reading data from databases "],
["exporting-data.html", "Chapter 6 Exporting data", " Chapter 6 Exporting data "],
["reshaping-data.html", "Chapter 7 Reshaping data", " Chapter 7 Reshaping data "],
["data-manipulation.html", "Chapter 8 Data manipulation", " Chapter 8 Data manipulation "],
["text-cleaning.html", "Chapter 9 Text-cleaning", " Chapter 9 Text-cleaning "],
["dates-and-times.html", "Chapter 10 Dates and times", " Chapter 10 Dates and times "],
["building-your-first-app.html", "Chapter 11 Building your first app", " Chapter 11 Building your first app "],
["user-interface-design.html", "Chapter 12 User Interface design", " Chapter 12 User Interface design "],
["custom-inputs-and-outputs.html", "Chapter 13 Custom inputs and outputs", " Chapter 13 Custom inputs and outputs "],
["reactive-expressions.html", "Chapter 14 Reactive expressions", " Chapter 14 Reactive expressions "],
["shiny-dashboarding.html", "Chapter 15 Shiny dashboarding", " Chapter 15 Shiny dashboarding "],
["code-style.html", "Chapter 16 Code style", " Chapter 16 Code style "],
["version-control.html", "Chapter 17 Version control", " Chapter 17 Version control "],
["testing-and-staging.html", "Chapter 18 Testing and staging", " Chapter 18 Testing and staging "]
]
